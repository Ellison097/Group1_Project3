\documentclass[12pt]{article}
\usepackage{subcaption}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{setspace}

\captionsetup[subfigure]{skip=0pt}
\setlength{\abovecaptionskip}{4pt}
\setlength{\belowcaptionskip}{4pt}

\geometry{a4paper, margin=1in}

% 设置行间距
\renewcommand{\baselinestretch}{0.001}
\setlength{\parskip}{0.001em}
\setlength{\itemsep}{0.001em}
\setlength{\parsep}{0.001em}
\setlength{\topsep}{0.001em}
\setlength{\partopsep}{0.001em}

% 设置代码样式
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    showstringspaces=false,
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    numbersep=1pt,
    frame=single,
    breaklines=true,
    postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space}
}

\title{Group1Project3}
\author{Licheng Guo, Yukun Gao, Qiming Zhang, Zining Hua, Yixuan Xu, Yongchen Lu}
\date{\today}


\begin{document}

\maketitle  
\begin{center}
  \href{https://ellison097.github.io/Group1_Project3/}{\texttt{https://ellison097.github.io/Group1\_Project3/}}
\end{center}

\tableofcontents
\newpage

\section{Introduction}

\subsection{Project Overview}
The Project represents a comprehensive data science analysis of the Federal Statistical Research Data Centers (FSRDC) ecosystem, focusing on 2,698 research outputs spanning from 2000 to 2025. This analysis provides unprecedented insights into the dynamics of academic research output and its broader implications for research management and policy development.

At its core, the project seeks to understand how research output evolves over time, how different RDCs contribute to the academic landscape, and what factors influence the impact of research publications. Our analysis reveals several key findings:

\begin{itemize}
    \item \textbf{Research Output Growth:} The number of publications increased from near zero in 2000 to approximately 260 per year by 2021-2022, with a slight decline in 2024-2025 (partial data). This 25-fold increase demonstrates the growing importance of FSRDC in academic research.
    
    \item \textbf{Top Performing RDCs:} Michigan, Boston, Chicago, Triangle, Baruch, Atlanta, Fed Board, Texas, Minnesota, and UCLA emerged as the most productive centers, collectively accounting for over 70\% of total outputs. This concentration highlights the role of institutional support and collaborative environments in research productivity.
    
    \item \textbf{Author Productivity:} John Haltiwanger leads with 74 publications, followed by Nathan Goldschlag (55) and Lucia Foster (52), demonstrating the concentration of research output among a few prolific authors. This pattern suggests the importance of sustained research engagement and expertise development.
    
    \item \textbf{Publication Types:} Journal articles dominate (over 90\% of outputs), with reports showing steady growth since 2005. Other categories (book chapters, dissertations, working papers) remain niche, indicating the preference for traditional academic dissemination channels.
    
    \item \textbf{Citation Patterns:} Citation distribution is highly skewed, with a median of 25 citations, mean of 111, and maximum of 10,952. Washington RDC achieves the highest median citations (103), followed by USC (57.5) and Triangle (49), suggesting varying levels of research impact across institutions.
\end{itemize}

Our methodology combines traditional statistical analysis with advanced machine learning techniques, providing a multi-dimensional understanding of research patterns:

\begin{itemize}
    \item \textbf{Data Processing:} Implemented a robust pipeline for data cleaning, deduplication, and enrichment using OpenAlex and Crossref APIs. The pipeline successfully processed 2,698 research outputs with comprehensive error handling for API rate limits and data inconsistencies.
    
    \item \textbf{Analysis Techniques:} Applied regression, classification (XGBoost achieving 78\% accuracy), PCA, clustering (K-Means, DBSCAN), and advanced NLP methods (BERT, LSTM). These techniques revealed complex patterns in research productivity and impact.
    
    \item \textbf{Innovative Approaches:} Developed novel combinations like BERT+K-Means+UMAP for topic modeling and implemented survival analysis for citation lifespan prediction. These methods provided deeper insights into research themes and impact trajectories.
\end{itemize}

\subsection{Project Architecture}
The project implements a comprehensive data processing and analysis pipeline for research output data. The architecture consists of the following components:

\subsubsection{Data Processing Pipeline}
\begin{enumerate}[label=\textbf{Step \arabic*:}]
    \item Raw Group Data $\rightarrow$ Cleaned Group Data
    \begin{itemize}
        \item \texttt{Code/clean\_data.py}
        \item \texttt{Code/convert\_float\_to\_int.py}
    \end{itemize}
    \item Cleaned Group Data $\rightarrow$ Combined Raw Data
    \begin{itemize}
        \item \texttt{Code/join\_and\_map\_data.py}
    \end{itemize}
    \item Combined Raw Data $\rightarrow$ Enriched Output Data
    \begin{itemize}
        \item \texttt{Code/enrich\_all\_combined\_data.py}
    \end{itemize}
    \item Enriched Output Data $\rightarrow$ Filtered \& Refined Output Data
    \begin{itemize}
        \item \texttt{Code/update\_venue\_column.py}
    \end{itemize}
    \item Filtered \& Refined Output Data $\rightarrow$ Final Enriched Dataset
    \begin{itemize}
        \item \texttt{Code/enrich\_all\_combined\_data\_metadata.py}
        \item \texttt{Code/enrich\_all\_combined\_data\_metadata2.py}
        \item \texttt{Code/enrich\_all\_combined\_data\_metadata3.py}
    \end{itemize}
    \item Final Enriched Dataset $\rightarrow$ Filtered Enriched Data
    \begin{itemize}
        \item \texttt{Code/filter\_enriched\_data.py}
    \end{itemize}
    \item Filtered Enriched Data $\rightarrow$ Citation Enriched Data
    \begin{itemize}
        \item \texttt{Code/enrich\_citations.py}
    \end{itemize}
    \item Citation Enriched Data $\rightarrow$ Insights \& Visualizations
    \begin{itemize}
        \item \texttt{Code/Group1\_Project3\_P1Q2(EDA)+P2(DataMining).ipynb}
    \end{itemize}
\end{enumerate}

\subsubsection{Directory Structure}
\begin{itemize}
    \item \texttt{Code/} - Contains all processing scripts
    \item \texttt{Project3\_Data/} - Raw data files
    \item \texttt{Project3\_Data\_Clean\_step1/} - First-stage cleaned data
    \item \texttt{Project3\_Data\_Clean\_step2/} - Second-stage processed data
    \item \texttt{Project\_Data\_Enriched\_Combined/} - Final enriched data
\end{itemize}

\subsubsection{Final Output Files}
\begin{itemize}
    \item \texttt{ResearchOutputs\_Group1.xlsx} - Final output for Part 1 (EDA Analysis)
    \begin{itemize}
        \item Contains cleaned and enriched data for Group 1
        \item Includes all necessary metadata and analysis results
    \end{itemize}
    \item \texttt{Combined\_ResearchOutputs\_Final.csv} - Final output for Part 2 (Data Mining)
    \begin{itemize}
        \item Contains combined and enriched data from all groups
        \item Includes citation data and additional metadata
    \end{itemize}
\end{itemize}

\subsection{Execution Guide and Screenshots}
\subsubsection{Environment Setup}
\begin{enumerate}
    \item Install required Python packages:
    \begin{lstlisting}[language=bash]
    pip install -r requirements.txt
    \end{lstlisting}
    \item Ensure all data files are in the correct directories:
    \begin{itemize}
        \item Raw data files in \texttt{Project3\_Data/}
        \item Reference files in root directory
    \end{itemize}
\end{enumerate}

\subsubsection{Execution Steps}
The pipeline can be executed in four different ways:

\begin{enumerate}
    \item Run the entire pipeline:
    \begin{lstlisting}[language=bash]
    python main.py
    \end{lstlisting}
    
    \item Run specific stages:
    \begin{lstlisting}[language=bash]
    python main.py --stage [stage_number]
    \end{lstlisting}
    Available stages:
    \begin{itemize}
        \item 1: Data cleaning and deduplication
        \item 2: Data mapping and consolidation
        \item 3: Output-level enrichment
        \item 4: Post-enrichment filtering
        \item 5: Project metadata enrichment
        \item 6: Final data processing
        \item 7: EDA analysis
    \end{itemize}
    
    \item Run with custom configuration:
    \begin{lstlisting}[language=bash]
    python main.py --config config.json
    \end{lstlisting}
    
    \item Run with specific output directory:
    \begin{lstlisting}[language=bash]
    python main.py --output-dir custom_output_directory
    \end{lstlisting}
\end{enumerate}

\begin{figure}[!p]
  \centering
  
  %——— 第1张 ———
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width=\linewidth]{截屏2025-04-28 上午9.32.26.png}
    \caption{Output 1}
    \label{fig:out1}
  \end{subfigure}
  
  \vspace{2pt} % 微小垂直间距
  
  %——— 第2张 ———
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width=\linewidth]{截屏2025-04-28 上午9.32.32.png}
    \caption{Output 2}
    \label{fig:out2}
  \end{subfigure}
  
  \vspace{2pt}
  
  %——— 第3张 ———
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width=\linewidth]{截屏2025-04-28 上午9.32.42.png}
    \caption{Output 3}
    \label{fig:out3}
  \end{subfigure}
  
  \vspace{2pt}
  
  %——— 第4张 ———
  \begin{subfigure}{0.5\textwidth}
    \includegraphics[width=\linewidth]{截屏2025-04-28 上午9.35.38.png}
    \caption{Output 4}
    \label{fig:out4}
  \end{subfigure}
  
  \caption{Code execution outputs showing different stages of the pipeline}
  \label{fig:all_outputs}
\end{figure}



\section{Input Processing}

\subsection{Data Processing Logic and Steps}

\subsubsection{Data Cleaning and Deduplication}
\begin{itemize}
    \item \textbf{Purpose}: Cleans individual group CSV files by removing duplicates against a reference dataset and then deduplicates across all group files.
    \item \textbf{Input}: Raw CSV files, Reference Excel
    \item \textbf{Output}: Cleaned and deduplicated group files
    \item \textbf{Command}:
    \begin{lstlisting}[language=bash]
    python Code/clean_data.py
    \end{lstlisting}
\end{itemize}

\subsubsection{Data Mapping and Consolidation}
\begin{itemize}
    \item \textbf{Purpose}: Combines the cleaned group files into a single dataset, mapping heterogeneous columns to a standardized schema.
    \item \textbf{Input}: Cleaned group files
    \item \textbf{Output}: Combined raw dataset
    \item \textbf{Command}:
    \begin{lstlisting}[language=bash]
    python Code/join_and_map_data.py
    \end{lstlisting}
\end{itemize}

\subsubsection{Output-Level Enrichment}
\begin{itemize}
    \item \textbf{Purpose}: Enriches the combined dataset with detailed bibliographic information using OpenAlex and Crossref APIs.
    \item \textbf{Input}: Combined raw dataset
    \item \textbf{Output}: Enriched dataset
    \item \textbf{Command}:
    \begin{lstlisting}[language=bash]
    python Code/enrich_all_combined_data.py --output "Project_Data_Enriched_Combined/combined_mapped_data_raw_enriched_final.csv"
    \end{lstlisting}
\end{itemize}

\subsubsection{Post-Enrichment Filtering and Venue Refinement}
\begin{itemize}
    \item \textbf{Purpose}: Filters the enriched dataset to keep only FSRDC-related records with DOIs.
    \item \textbf{Input}: Output from previous step
    \item \textbf{Output}: Filtered and venue-refined dataset
    \item \textbf{Command}:
    \begin{lstlisting}[language=bash]
    python Code/update_venue_column.py \
        --input "Project_Data_Enriched_Combined/combined_mapped_data_raw_enriched_final.csv" \
        --output "Project_Data_Enriched_Combined/combined_mapped_data_raw_enriched_final_final.csv"
    \end{lstlisting}
\end{itemize}

\subsubsection{Project Metadata Enrichment}
\begin{itemize}
    \item \textbf{Purpose}: Enriches the filtered dataset with project-level information using multiple metadata sources.
    \item \textbf{Input}: Filtered/refined dataset, Metadata Excel, Research Outputs Excel
    \item \textbf{Outputs}: Intermediate and final enriched files
    \item \textbf{Commands}:
    \begin{enumerate}
        \item Stage 1: PI Matching
        \item Stage 2: Title Matching
        \item Stage 3: Researcher Matching
    \end{enumerate}
\end{itemize}

\subsubsection{Error Handling and Logging}
\begin{itemize}
    \item \textbf{Error Types and Handling}:
    \begin{itemize}
        \item API Rate Limiting
        \begin{itemize}
            \item Implementation of exponential backoff strategy
            \item Maximum retry attempts: 5
            \item Backoff factor: 2 (doubles wait time between retries)
            \item Example code:
            \begin{lstlisting}[language=Python]
            def handle_rate_limit(response, max_retries=5):
                if response.status_code == 429:
                    retry_after = int(response.headers.get('Retry-After', 60))
                    for attempt in range(max_retries):
                        time.sleep(retry_after * (2 ** attempt))
                        # Retry the request
            \end{lstlisting}
        \end{itemize}
        
        \item Network Errors
        \begin{itemize}
            \item Connection timeout handling
            \item DNS resolution errors
            \item SSL/TLS errors
            \item Example code:
            \begin{lstlisting}[language=Python]
            try:
                response = requests.get(url, timeout=30)
            except requests.exceptions.RequestException as e:
                logger.error(f"Network error: {str(e)}")
                # Implement fallback strategy
            \end{lstlisting}
        \end{itemize}
        
        \item Data Format Errors
        \begin{itemize}
            \item JSON parsing errors
            \item CSV format validation
            \item Data type conversion errors
            \item Example code:
            \begin{lstlisting}[language=Python]
            def validate_data_format(data):
                required_fields = ['title', 'doi', 'authors']
                for field in required_fields:
                    if field not in data:
                        raise DataFormatError(f"Missing required field: {field}")
            \end{lstlisting}
        \end{itemize}
        
        \item File I/O Errors
        \begin{itemize}
            \item File permission issues
            \item Disk space monitoring
            \item File corruption detection
            \item Example code:
            \begin{lstlisting}[language=Python]
            def safe_file_operation(file_path, operation):
                try:
                    with open(file_path, 'r') as f:
                        return operation(f)
                except IOError as e:
                    logger.error(f"File operation failed: {str(e)}")
                    # Implement recovery strategy
            \end{lstlisting}
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Error Recovery Strategies}:
    \begin{itemize}
        \item Retry Mechanisms
        \begin{itemize}
            \item Configurable retry counts
            \item Progressive backoff
            \item Circuit breaker pattern
        \end{itemize}
        
        \item Fallback Strategies
        \begin{itemize}
            \item Alternative data sources
            \item Cached data usage
            \item Partial data processing
        \end{itemize}
        
        \item Data Validation
        \begin{itemize}
            \item Input validation
            \item Output verification
            \item Data integrity checks
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Logging System}:
    \begin{itemize}
        \item Detailed Error Logs
        \begin{itemize}
            \item Error context capture
            \item Stack trace logging
            \item Error classification
        \end{itemize}
        
        \item Processing Statistics
        \begin{itemize}
            \item Success/failure rates
            \item Processing times
            \item Data volume metrics
        \end{itemize}
        
        \item Performance Metrics
        \begin{itemize}
            \item API call durations
            \item Memory usage
            \item CPU utilization
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{EDA Analysis Results and Visualizations}
\paragraph{\textbf{For interactive visual charts and more detailed analysis for each chart, please refer to\textit{Group1\_Project3\_P1Q2(EDA)+P2(DataMining).ipynb}}}\

We performed a comprehensive exploratory analysis of 2,698 research outputs from FSRDC centers. Below is a high-level synthesis of the main findings:

\begin{enumerate}
  \item \textbf{Publication Volume \& Growth}
    \begin{itemize}
      \item Total outputs rose from almost zero in 2000 to a peak of approximately 260 publications per year by 2021–2022, before declining in 2024–2025 (partial data).
      \item The top 10 RDCs by sheer volume are Michigan, Boston, Chicago, Triangle, Baruch, Atlanta, Fed Board, Texas, Minnesota, and UCLA, together accounting for the majority of outputs.
    \end{itemize}

  \item \textbf{Author Productivity}
    \begin{itemize}
      \item Among all authors, John Haltiwanger leads with 74 publications, followed by Nathan Goldschlag (55), Lucia Foster (52), and several others in the 30–45 range.
      \item A histogram of author counts shows most papers are single- or small-team efforts, with few large collaborations.
    \end{itemize}

  \item \textbf{Output Types \& Diversification}
    \begin{itemize}
      \item Journal articles (MI) dominate the portfolio (\(>90\%\) of outputs), but the share of reports (RE) has steadily grown since 2005.
      \item Other categories—book chapters, dissertations, working papers, data sets—remain niche (\(<5\text{--}10\) papers/year).
    \end{itemize}

  \item \textbf{Citation Distribution \& Skew}
    \begin{itemize}
      \item Citation counts are extremely right-skewed: median = 25, mean \(\approx 111\), 99th percentile \(\approx 1{,}475\), maximum = 10{,}952.
      \item Over 75\% of papers have \(\le88\) citations, and a handful of "blockbusters" drive the heavy tail.
    \end{itemize}

  \item \textbf{Citations Over Time}
    \begin{itemize}
      \item Early publications (pre-2010) enjoy higher mean/median citations, while recent years show lower per-paper citations due to citation lag.
      \item Publication volume and per-paper citations are inversely related over time: as output volume soared, mean/median citations per paper declined.
    \end{itemize}

  \item \textbf{RDC-Level Impact}
    \begin{itemize}
      \item Washington RDC achieves the highest median citations per paper (103), followed by USC (57.5) and Triangle (49).
      \item High-volume centers like Michigan and Boston show lower medians (28–42), reflecting broader citation variability.
    \end{itemize}

  \item \textbf{Venue-Level Impact}
    \begin{itemize}
      \item Top venues by median citation include British Journal of Pharmacology (256), QJE (248), Applied Geography (248), and Journal of Finance (244).
      \item This list spans biomedical, economics, engineering, and astrophysics outlets, underscoring interdisciplinary reach.
    \end{itemize}

  \item \textbf{Citation Velocity}
    \begin{itemize}
      \item When adjusted for age, certain recent works (e.g., the SciPy 1.0 paper) exhibit exceptionally high citations per year (\(>100/\text{year}\)), marking them as "fast risers."
    \end{itemize}

  \item \textbf{Inter-Variable Correlations}
    \begin{itemize}
      \item The only notable numeric correlation is a negative link between citations and publication year (\(r\approx -0.21\)), reflecting time-to-accumulate effects.
      \item Other metadata fields (month, volume, issue, pages) show negligible correlations with citation impact.
    \end{itemize}
\end{enumerate}

\paragraph*{Conclusion}
FSRDC outputs have grown dramatically over 25 years, concentrated in journal articles and a handful of prolific authors and centers. Citation impact follows a classic long-tail pattern: most works receive modest attention, while a small subset achieves extraordinary influence. Venue choice, publication timing, and citation velocity reveal strategic levers for maximizing research visibility.


\section{Using Python for Data Science Applications}
\paragraph{\textbf{For interactive visual charts and more detailed analysis for each chart, please refer to\textit{Group1\_Project3\_P1Q2(EDA)+P2(DataMining).ipynb}}}\

\begin{enumerate}
  \item \textbf{Overview and Exploratory Data Analysis (EDA)}\\
    Through detailed exploratory analysis, we observed the following major insights from the combined dataset of research outputs:
    \begin{itemize}
      \item \textbf{Publication Trends:}  
        Research activity significantly increased from 2000 to 2023, with clear peaks in recent years. RDCs such as Michigan, Boston, Chicago, and Triangle are notably productive, indicating strong institutional support and collaborative environments.
      \item \textbf{Author Productivity:}  
        Key prolific authors identified include John Haltiwanger, Nathan Goldschlag, Lucia Foster, and Javier Miranda. These authors significantly contributed to the dataset, highlighting influential research leaders.
      \item \textbf{Citation Analysis:}  
        Citation distributions showed heavy skewness with most publications having low citation counts, while a small subset had exceptionally high citations (e.g., top-cited papers with thousands of citations). Citation analysis by RDC revealed institutions like Washington, USC, and Berkeley excel in producing highly cited research. Journal venues such as \textit{The Quarterly Journal of Economics}, \textit{Journal of Econometrics}, and \textit{Journal of Financial Economics} consistently published highly impactful work.
    \end{itemize}

  \item \textbf{Regression and Classification Modeling Insights}\\
    Initial attempts at using regression (predicting citation counts directly) showed limited effectiveness due to inherent variability and outlier effects in citations, making it challenging to model accurately.

    Thus, the problem was reframed as a binary classification (high vs.\ low citation counts):
    \begin{itemize}
      \item \textbf{Baseline Logistic Regression:} Achieved moderate performance, suggesting some predictability in citation popularity based on publication metadata.
      \item \textbf{Advanced Models (Decision Tree, Random Forest, XGBoost, Neural Networks):} Improved accuracy significantly, with XGBoost delivering the strongest performance (Accuracy: 78\%, ROC-AUC: 86\%). This indicates that complex nonlinear relationships exist between metadata (publication type, year, RDC) and citation outcomes.
    \end{itemize}

  \item \textbf{Principal Component Analysis (PCA) Insights}\\
    PCA analysis showed clear dimensional structure in the dataset. Although the first two principal components explained limited variance (around 40\%), they provided useful clustering signals, suggesting latent patterns or groups within publication attributes. Visualization highlighted distinct clusters, particularly when considering RDC and Output Type combinations.

  \item \textbf{Clustering Insights}\\
    Three distinct clustering methodologies were employed:
    \begin{itemize}
      \item \textbf{K-Means Clustering:} Identified distinct groups based on publication metadata, providing insights into groups with inherently high or low citation potentials.
      \item \textbf{Hierarchical Clustering (Agglomerative):} Revealed hierarchical relationships and substructures within publications, further detailing potential strategic groups for targeted analysis or investment.
      \item \textbf{DBSCAN:} Identified robust clusters and effectively managed noise, indicating strong intrinsic grouping structures tied to institutional attributes and publication venues.
    \end{itemize}
    The clusters consistently revealed that certain RDCs and output types naturally group together, reflecting common research themes or shared citation trajectories.

  \item \textbf{Advanced NLP Methods}\\
    Multiple text-based methods revealed deep insights from the output titles:
    \begin{itemize}
      \item \textbf{TF-IDF Analysis:} Highlighted key terms such as "economic," "market," and "analysis," suggesting dominant economic and market-oriented research topics.
      \item \textbf{LDA Topic Modeling:} Successfully identified coherent thematic groups such as:
        \begin{itemize}
          \item Economic Policy \& Markets
          \item Health \& Medical Research
          \item Machine Learning \& AI
          \item Financial \& Investment Analysis
          \item Social \& Demographic Studies
        \end{itemize}
      \item \textbf{BERT + K-Means + UMAP:} Leveraged semantic embeddings for sophisticated clustering, revealing nuanced topic groupings not visible through simpler methods. Embeddings allowed deeper semantic topic interpretation and identification of hidden thematic relationships.
      \item \textbf{Fine-Tuned BERT \& LSTM Classification Models:} Demonstrated robust predictive capabilities of citation popularity from textual data alone, emphasizing the predictive power of nuanced textual features within titles.
    \end{itemize}

  \item \textbf{Innovative Advanced Analytics Insights}\\
    Beyond conventional analyses, advanced analytical techniques provided further valuable insights:
    \begin{itemize}
      \item \textbf{LSTM Deep Learning Models:} Captured complex sequential patterns in textual data, achieving strong predictive performance on citation popularity, reinforcing the value of deep textual analysis.
      \item \textbf{Survival Analysis (Citation Lifespan):} Highlighted distinct citation trajectories and the "citation life-cycle," revealing how quickly citations accumulate or plateau across different publication types and RDCs.
      \item \textbf{Dynamic BERTopic Modeling:} Unveiled temporal shifts in research themes, highlighting evolving research priorities such as the rising importance of AI and machine learning topics in recent years.
      \item \textbf{Co-Authorship Network Analysis:} Revealed robust collaborative networks, influential research communities, and key academic influencers who are central to knowledge dissemination and innovation.
    \end{itemize}
\end{enumerate}

\paragraph{Final Summary of Insights}
The comprehensive analysis revealed several critical insights:
\begin{itemize}
  \item \textbf{Citation Prediction:} Advanced classification models effectively predict high-impact research, especially leveraging metadata and sophisticated text embeddings.
  \item \textbf{Topic Evolution:} Research topics dynamically shift over time, highlighting the emergence and growing dominance of technology, health sciences, and economic policy topics.
  \item \textbf{Institutional Strength:} Certain RDCs consistently produce highly impactful research, indicating institutional specialization and strong research ecosystems.
  \item \textbf{Collaboration Networks:} Identifying influential researchers and collaborative structures can strategically enhance future research productivity and innovation.
  \item \textbf{Data-Driven Decision-Making:} Leveraging advanced techniques (deep NLP, survival analysis, dynamic topic modeling) provides actionable insights to guide strategic planning, resource allocation, and research agenda-setting.
\end{itemize}

\section{GitHub Pages Site}
\href{https://ellison097.github.io/Group1_Project3}{\texttt{https://ellison097.github.io/Group1\_Project3}}

\section{Conclusion}
The Project has successfully demonstrated the transformative potential of data science in academic research analysis. Through an innovative combination of traditional statistical methods and advanced machine learning techniques, we have developed a comprehensive understanding of research output patterns within the FSRDC ecosystem. Our key findings and contributions include:

\begin{itemize}
    \item \textbf{Data Processing Pipeline:} Developed an efficient pipeline that processes 2,698 research outputs, implementing robust error handling for API rate limits, network issues, and data format inconsistencies. The pipeline successfully enriched data with citation information and metadata from multiple sources, ensuring data quality and consistency throughout the analysis process.
    
    \item \textbf{Research Productivity Analysis:} Identified clear patterns in research output growth, showing a 25-fold increase from 2000 to 2022. Our analysis revealed that 10 RDCs account for over 70\% of total outputs, with Michigan, Boston, and Chicago leading in volume. This concentration of research output has important implications for resource allocation and research policy.
    
    \item \textbf{Impact Assessment:} Demonstrated that citation impact follows a power-law distribution, with Washington RDC achieving the highest median citations (103). Our analysis showed that early publications (pre-2010) enjoy higher citation rates, while recent works show lower rates due to citation lag. These findings provide valuable insights for research evaluation and impact prediction.
    
    \item \textbf{Advanced Analytics:} Successfully applied machine learning techniques:
    \begin{itemize}
        \item XGBoost achieved 78\% accuracy in predicting high-impact research
        \item BERT+K-Means+UMAP identified 5 distinct research themes
        \item Survival analysis revealed citation accumulation patterns
    \end{itemize}
    These techniques enabled us to extract meaningful patterns from research titles and metadata, revealing underlying themes and trends that would otherwise remain hidden.
    
    \item \textbf{Practical Applications:} Our findings have direct implications for:
    \begin{itemize}
        \item Research funding allocation based on RDC productivity and impact
        \item Collaboration strategy development using co-authorship networks
        \item Publication venue selection based on citation patterns
        \item Early identification of high-impact research using our predictive models
    \end{itemize}
    These applications demonstrate the project's value for research management and policy development.
\end{itemize}

Looking forward, the project opens several promising avenues for future research and development:

\begin{itemize}
    \item Incorporating grant funding data to analyze research investment impact
    \item Developing real-time monitoring systems for research impact
    \item Extending the analysis to include more recent publications
    \item Creating interactive visualization tools for research stakeholders
\end{itemize}

This project represents a significant step forward in the application of data science to academic research analysis. By combining rigorous methodology with practical applications, we have created a framework that can guide future studies in academic impact analysis. The project's findings and methodologies provide a foundation for data-driven decision-making in research management, contributing to the ongoing evolution of evidence-based research policy and practice.

The success of this project underscores the importance of interdisciplinary collaboration between data science and academic research management. As we continue to refine our methods and expand our analysis, we can look forward to even deeper insights into the complex dynamics of academic research and its impact on society. This project serves not only as a comprehensive analysis of the FSRDC ecosystem but also as a model for future research in academic analytics and impact assessment.

\end{document} 